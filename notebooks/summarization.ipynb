{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "266729f4-9377-4972-ac44-8bf63afa6717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/Users/yaser/.pyenv/versions/3.11.1/lib/python3.11/site-packages/transformers/pytorch_utils.py:335: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: these Terms of Service reect the way Google’s business works, the laws that apply to our company, and certain things we’ve always believed to be true . these terms include: what you can expect from us, which describes how we provide and develop our services What we expect from you, which establishes certain rules for using our services Content in Google services .\n"
     ]
    }
   ],
   "source": [
    "%store -r document_text\n",
    "from transformers import pipeline\n",
    "\n",
    "# load the summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"t5-small\")\n",
    "\n",
    "# summarize the document text (you can summarize parts if the document is too large)\n",
    "summary = summarizer(document_text[:1000], max_length=150, min_length=30, do_sample=False)\n",
    "print(\"Summary:\", summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39ab0ef7-39d5-4251-ba1e-92b1884465fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'passages' (list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yaser/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/yaser/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# split text into sentences\n",
    "sentences = sent_tokenize(document_text)\n",
    "\n",
    "# combine sentences into passages\n",
    "passages = []\n",
    "current_passage = \"\"\n",
    "for sentence in sentences:\n",
    "    if len(current_passage.split()) + len(sentence.split()) < 200:  # adjust the word limit as needed\n",
    "        current_passage += \" \" + sentence\n",
    "    else:\n",
    "        passages.append(current_passage.strip())\n",
    "        current_passage = sentence\n",
    "if current_passage:\n",
    "    passages.append(current_passage.strip())\n",
    "%store passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58f1c09-5dc9-4340-98cd-1bb9ac3c12dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
